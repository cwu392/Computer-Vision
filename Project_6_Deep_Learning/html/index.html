<html>
<head>
<title>Deep Learning Project</title>
<link href='http://fonts.googleapis.com/css?family=Nunito:300|Crimson+Text|Droid+Sans+Mono' rel='stylesheet' type='text/css'>
<link rel="stylesheet" title="Default" href="styles/github.css">
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>  

<link rel="stylesheet" href="highlighting/styles/default.css">
<script src="highlighting/highlight.pack.js"></script>

<style type="text/css">
body {
	margin: 0px;
	width: 100%;
	font-family: 'Crimson Text', serif;
	font-size: 20px;
	background: #fcfcfc;
}
h1 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 28px;
	margin: 25px 0px 0px 0px;
	text-transform: lowercase;

}

h2 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 32px;
	margin: 15px 0px 35px 0px;
	color: #333;	
	word-spacing: 3px;
}

h3 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 26px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}
h4 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 22px;
	margin: 10px 0px 10px 0px;
	color: #333;
	word-spacing: 2px;
}

h5 {
	font-family: 'Nunito', sans-serif;
	font-weight: normal;
	font-size: 18px;
	margin: 10px 0px 10px 0px;
	color: #111;
	word-spacing: 2px;
}

p, li {
	color: #444;
}

a {
	color: #DE3737;
}

.container {
	margin: 0px auto 0px auto;
	width: 1160px;
}

#header {
	background: #333;
	width: 100%;
}

#headersub {
	color: #ccc;
	width: 960px;
	margin: 0px auto 0px auto;
	padding: 20px 0px 20px 0px;
}

.chart {
	width: 480px;
}
.lol {
	font-size: 16px;
	color: #888;
	font-style: italic;
}
.sep {
	height: 1px;
	width: 100%;
	background: #999;
	margin: 20px 0px 20px 0px;
}
.footer{
	font-size: 16px;
}
.latex {
	width: 100%;
}

.latex img {
	display: block;
	margin: 0px auto 0px auto;
}

pre {
	font-family: 'Droid Sans Mono';
	font-size: 14px;
}

table td {
  text-align: center;
  vertical-align: middle;
}

table td img {
  text-align: center;
  vertical-align: middle;
}

#contents a {
}
</style>
<script type="text/javascript">
    hljs.initHighlightingOnLoad();
</script>
</head>
<body>
<div id="header" >
<div id="headersub">
<h1>Chiamin Wu </h1>
</div>
</div>
<div class="container">

<h2> Project 6 / Deep Learning</h2>

<p> 	In Project 6, we are assigned to design a deep convolutional neural network for 15-Scenes Recognition. Before we start, let's take a look at our previous result (Table I) in Project 4. In our previous project, I used Bag-of-SIFT+Linear SVM to get accuracy ~60% and used GMM and Fisher Encoding+RBF Kernel to achieve accuracy ~82%. In Part 1 of this project, I will build a shallow network (less than 10 layers) to achieve accuracy ~50%. In Part 2, I will use a pretrained VGG model (23 layers) to improve my accuracy up to 90%.</p>

</p>
<center>
<table border="1">
<tr>
<th>Feature Representation</th>
<th>Classifier</th>
<th>Best Accuracy(%)</th>
</tr>
<tr>
<td>Tiny images</td>
<td>1-Nearest Neighbor</td>
<td>15.3%</td>
</tr>
<tr>
<td>Bag of SIFT</td> 
<td>1-Nearest Neighbor</td>
<td>50.4%</td>
</tr>
<tr>
<td>Bag of SIFT</td> 
<td>Linear SVM</td>
<td>57.5%</td>
</tr>
<tr>
<td>Bag of SIFT</td>
<td>Non-linear SVM</td>
<td>70.0%</td>
</tr>
<tr>
<td>GMM & Fisher encoding</td> 
<td>Non-linear SVM</td>
<td>80.1%</td>
</tr>
<tr>
<td>GMM & Fisher encoding</td> 
<td>SVM RBF Kernel (libsvm)</td>
<td>81.8%</td>
</tr>
</tr>
<tr>
<td>Shallow Convolutional Neural Network</td> 
<td>Composed only 6 layers</td>
<td>55.5%</td>
</tr>
<tr>
<td>Deep Convolutional Neural Network</td> 
<td>Modified VGG-F with 23 layers</td>
<td>90.3%</td>
</tr>
</table>
</center>
<p></p>

<h3>Part I: Shallow Convolutional Neural Network</h3>

<p>In this part, I build a convolutional neural network from scratch. Then, I to step by step improve its performance. I used tricks like image augmentation, batch normalization and dropout and made a table to visualize their influence.</p>

Table of Steps and its Performance:
</p>
<center>
<table border="1">
<tr>
<th>Name</th>
<th>Feature</th>
<th>Accuracy(%)</th>
</tr>
<tr>
<td>Random Guess</td>
<td>Random Guess from 15 categories</td>
<td>6.6%</td>
</tr>
<tr>
<td>Shallow CNN (Base Line)</td> 
<td>CNN with 6 layers</td>
<td>28.9%</td>
</tr>
<tr>
<td>Data Augmentation (Jitter)</td> 
<td>Random Flip Image</td>
<td>34.3%</td>
</tr>
<tr>
<td>Normalization (w/o Jitter)</td>
<td>Image with Zero Mean w/o Jitter</td>
<td>47.0%</td>
</tr>
</tr>
<tr>
<td>Dropout</td>
<td>Dropout 50% Connections</td>
<td>48.9%</td>
</tr>
<tr>
<td>Normalization (w/i Jitter)</td>
<td>Image with Zero Mean w/i Jitter</td>
<td>52.1%</td>
</tr>
<tr>
<td>Batch Normalization</td>
<td>Normalize Batch after Activation</td>
<td>55.5%</td>
</tr>
</table>
</center>
<p></p>

Visualization of the Shallow Neural Network with 6 layers:<br>
<img src="Part1_Scheme.jpg" width="50%"/>
<br>Visualization of Learned Filters:<br>
<img src="Part1_Filters.jpg" width="45%"/>
<br>Performance:<br>
<img src="Part1_Performance.jpg" width="60%"/>

<h3>Part II: Deep Convolutional Neural Network from VGG-F</h3>
<p>In this part, I first change the input image from grey to RGB with resolution 224x224 to meet the input format of VGG. After this, I normalize my images. To adjust our goal from 1000-classification to 15-Scenes, I change the FC8 layer in VGG-F. Specifically, FC8 was a fully-connected layer with input size 4096 and output size 1000. To output 15 categories, I change the original 1000 classes to 15. In addition, I also add 2 dropout layers between FC6 to FC7 and FC7 to FC8, which is the same as default VGG netork but lost in our download mat file.</p>

<br>Visualization of the modified VGG Network:<br>
<img src="Part2_Scheme.jpg" width="130%"/>
<br>Visualization of Learned Filters:<br>
<img src="Part2_Layer1_Filters.jpg" width="40%"/>

<br>Performance:<br>
<img src="Part2_Performance.jpg" width="60%"/>
<h3>Part III: Extra Credit in Deep Dream Visualization (+10%)</h3>
<p>In this part, I extract features from all convolutional layers and create figures to verify its result. I implemented a 30 channels result from layer 5, 9, 13, 16 and 19. We can easily figure out in first 2 convolutional layers, our results are composed only lines. In layer 11 and 13, we can start to see shapes. In the last 2 layers, there are more abstract shapes in our figure. Code named: DeepDreamVisualization.m</p>

<img src="dd_layer5.jpg" width="35%"/>
<img src="dd_layer9.jpg" width="38%"/>
<img src="dd_layer11.jpg" width="40%"/>
<img src="dd_layer13.jpg" width="40%"/>
<img src="dd_layer16.jpg" width="40%"/>
<img src="dd_layer19.jpg" width="40%"/>

</body>
</html>
